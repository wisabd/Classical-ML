{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this notebook is to show the use of LSTMs for processing sequences. \n",
        "\n",
        "Specifically, we try to compute the sum of two binay digits,\n",
        "delegating to the model the task of taking care of the propagation of the carry."
      ],
      "metadata": {
        "id": "Zw_326KLT9dF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ynz-4_4cFmbJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, LSTM, Conv1D, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is our generator. Each element of the resulting batch is a pair (a,res)\n",
        "where a[0] and a[1] are two sequences of lenght seqlen of binary digits, and\n",
        "res is their sum. The digits are supposed to be represented in a positional order with less significative digits at lower positions (left to rigth).\n",
        "\n",
        "The initial carry of the generator is 0; at successive invocations it \n",
        "reuses the final carry of the previous sum."
      ],
      "metadata": {
        "id": "iA01pkKbUt7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generator(batchsize,seqlen):\n",
        "    init_carry = np.zeros(batchsize)\n",
        "    carry = init_carry\n",
        "    while True:\n",
        "      #print(\"initial carry = \", carry)\n",
        "      a = np.random.randint(2,size=(batchsize,seqlen,2))\n",
        "      res = np.zeros((batchsize,seqlen))\n",
        "      for t in range(0,seqlen):\n",
        "        sum = a[:,t,0]+a[:,t,1] + carry\n",
        "        res[:,t] = sum % 2\n",
        "        carry = sum // 2\n",
        "      yield (a, res)"
      ],
      "metadata": {
        "id": "IXSV0bfjF64L"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create an instance of the generator."
      ],
      "metadata": {
        "id": "ZF-jlaqAWc2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = generator(1,2)"
      ],
      "metadata": {
        "id": "Ov3rXaLVHDCT"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now let's see a few samples."
      ],
      "metadata": {
        "id": "b4hntQtSWjPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a,res = next(gen)\n",
        "print(\"a1 = {}, a2={}. res = {}\".format(a[0,:,0],a[0,:,1],res[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM7R8ZZZHN7p",
        "outputId": "bb0e07ae-9efe-4644-ed04-a3417a46ed73"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a1 = [1 0], a2=[1 1]. res = [0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now define the model. It takes in input a pair of boolean sequences of unspecified length. The batchsize dimension is, as usual, implicit too."
      ],
      "metadata": {
        "id": "dD8Yg_HnWqYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_model():\n",
        "    xa = Input(shape=(None,2))\n",
        "    x = Conv1D(8,1,activation='relu')(xa)\n",
        "    x = Conv1D(4,1,activation='relu')(x)\n",
        "    #x = xa\n",
        "    x = LSTM(4,activation=None, return_sequences=True)(x)\n",
        "    x = Dense(1,activation='sigmoid')(x)\n",
        "    out = tf.squeeze(x,2)\n",
        "    #out = x\n",
        "    comp = Model(inputs=xa, outputs=out)\n",
        "    return comp"
      ],
      "metadata": {
        "id": "_8FmUlpPOfcG"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mymodel = gen_model()\n",
        "mymodel.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHhEwRibOpgV",
        "outputId": "5f4d7095-b28b-4764-cc44-abf93aca0d39"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_13 (InputLayer)       [(None, None, 2)]         0         \n",
            "                                                                 \n",
            " conv1d_12 (Conv1D)          (None, None, 8)           24        \n",
            "                                                                 \n",
            " conv1d_13 (Conv1D)          (None, None, 4)           36        \n",
            "                                                                 \n",
            " lstm_12 (LSTM)              (None, None, 4)           144       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, None, 1)           5         \n",
            "                                                                 \n",
            " tf.compat.v1.squeeze_7 (TFO  (None, None)             0         \n",
            " pLambda)                                                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 209\n",
            "Trainable params: 209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mymodel.compile(optimizer='adam',loss='mse')"
      ],
      "metadata": {
        "id": "VHiUjmFKQB_p"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batchsize=100\n",
        "seqlen=10"
      ],
      "metadata": {
        "id": "wQwv4HCfQn11"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mymodel.load_weights(\"weights/lstm.hdf5\")"
      ],
      "metadata": {
        "id": "zsV-U31gQdsl"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mymodel.fit(generator(batchsize,seqlen), steps_per_epoch=100, epochs=100)\n",
        "#comp.save_weights(\"weights/lstm.hdf5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSAUJlQnQWht",
        "outputId": "fda8abd0-4292-45c1-c227-9017ebcbf3f9"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 2s 7ms/step - loss: 0.2512\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2500\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2500\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2500\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2499\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2499\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2498\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.2496\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2492\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2481\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2451\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2367\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.2168\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.1978\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.1785\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.1605\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.1450\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.1330\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.1206\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.1114\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1029\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0958\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0909\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0869\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0833\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0795\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0777\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0763\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0737\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0732\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0722\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0705\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0697\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0694\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0699\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0679\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0669\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0654\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0663\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0653\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0654\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0650\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0637\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0648\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0630\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0632\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0627\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0616\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0624\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0611\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0615\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0606\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0600\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0603\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0603\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0603\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0606\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0606\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0600\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0602\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0584\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0590\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0591\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0589\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0586\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0586\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0582\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0578\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0586\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0580\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0576\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0576\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0585\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0571\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0580\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0569\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0574\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0574\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0569\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0569\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0576\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0564\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0571\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0572\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0562\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0559\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0565\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0550\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0548\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0550\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0559\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0554\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0557\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0551\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0558\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0542\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0551\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0548\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.0545\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0550\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4c0356a490>"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example,res = next(generator(1,10))\n",
        "predicted = np.array([int(np.rint(x)) for x in mymodel.predict(example)[0]])\n",
        "\n",
        "print(\"a1        = {}\".format(example[0][:,0].astype(int)))\n",
        "print(\"a2        = {}\".format(example[0][:,1].astype(int)))\n",
        "print(\"expected  = {}\".format(res[0].astype(int)))\n",
        "print(\"predicted = {}\".format(predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCI2sFv5SJ7O",
        "outputId": "231ff033-f6cb-4e14-e57a-abbf7d870249"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "a1        = [1 0 0 0 1 0 0 0 0 1]\n",
            "a2        = [0 0 0 1 0 0 0 1 1 0]\n",
            "expected  = [1 0 0 1 1 0 0 1 1 1]\n",
            "predicted = [1 1 0 1 1 0 0 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WOW!"
      ],
      "metadata": {
        "id": "-bU4ykMqXLan"
      }
    }
  ]
}
